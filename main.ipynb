{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7IoIMEy4xjCG"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Embedding, Dense, Dropout, Bidirectional, LSTM, Input, GlobalAveragePooling1D, Flatten, GRU, LayerNormalization\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from pyvi import ViTokenizer\n",
    "from pyvi import ViUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_AZX9BufyCn4"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "oShBZG5RyDpW",
    "outputId": "6d11dabd-cdbb-42c6-f73f-f50ddcebcb97"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "MaRmX8NzyEYk",
    "outputId": "d32af3b0-9055-405e-c7a5-300835a6d31b"
   },
   "outputs": [],
   "source": [
    "sentiment_data = pd.DataFrame({'input': data['Comment Text'], 'label': data['Manual label']})\n",
    "sentiment_data = sentiment_data.dropna()\n",
    "sentiment_data = sentiment_data.reset_index(drop=True)\n",
    "sentiment_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B838586fyGqn"
   },
   "outputs": [],
   "source": [
    "input_data = sentiment_data['input'].values\n",
    "input_label = sentiment_data['label'].values\n",
    "\n",
    "label_dict = {'NEG':0, 'NEU':1, 'POS':2}\n",
    "# label_dict = {0:\"NEG\", 1:\"NEU\", 2:\"POS\"}\n",
    "\n",
    "input_pre = []\n",
    "label_with_accent = []\n",
    "for idx, dt in enumerate(input_data):\n",
    "  input_text_pre = list(tf.keras.preprocessing.text.text_to_word_sequence(dt))\n",
    "  input_text_pre = \" \".join(input_text_pre)\n",
    "  input_text_pre_no_accent = str(ViUtils.remove_accents(input_text_pre).decode(\"utf-8\"))\n",
    "  input_text_pre_accent = ViTokenizer.tokenize(input_text_pre)\n",
    "  input_text_pre_no_accent = ViTokenizer.tokenize(input_text_pre_no_accent)\n",
    "  input_pre.append(input_text_pre_accent)\n",
    "  input_pre.append(input_text_pre_no_accent)\n",
    "  label_with_accent.append(input_label[idx])\n",
    "  label_with_accent.append(input_label[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLot Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    start_idx = i * 1000\n",
    "    end_idx = (i + 1) * 1000\n",
    "    seq_len = [len(j.split()) for j in input_pre[start_idx:end_idx]]\n",
    "    pd.Series(seq_len).hist(bins=10, ax=ax)\n",
    "    ax.set_title(f'From {start_idx} to {end_idx-1}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6hViJPCMyG7c",
    "outputId": "4f4da2e8-cb28-4c17-c5b9-f5ce3b2d2581"
   },
   "outputs": [],
   "source": [
    "# seq_len = [len(i.split()) for i in input_pre[0:1000]]\n",
    "# pd.Series(seq_len).hist(bins = 10, figsize=(20,15))\n",
    "# plt.show()\n",
    "\n",
    "# seq_len = [len(i.split()) for i in input_pre[1000:2000]]\n",
    "# pd.Series(seq_len).hist(bins = 10)\n",
    "# plt.show()\n",
    "\n",
    "# seq_len = [len(i.split()) for i in input_pre[2000:3000]]\n",
    "# pd.Series(seq_len).hist(bins = 10)\n",
    "# plt.show()\n",
    "\n",
    "# seq_len = [len(i.split()) for i in input_pre[3000:4000]]\n",
    "# pd.Series(seq_len).hist(bins = 10)\n",
    "# plt.show()\n",
    "\n",
    "# seq_len = [len(i.split()) for i in input_pre[4000:5000]]\n",
    "# pd.Series(seq_len).hist(bins = 10)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cSl378XXyHMH",
    "outputId": "1ad025d5-264f-4088-a9e7-6dec4bf290c0"
   },
   "outputs": [],
   "source": [
    "label_idx = [i for i in label_with_accent]\n",
    "label_tf = tf.keras.utils.to_categorical(label_idx, num_classes = 3, dtype = 'float32')\n",
    "\n",
    "tokenizer_data = Tokenizer(oov_token = '<OOV>', filters = '', split = ' ')\n",
    "tokenizer_data.fit_on_texts(input_pre)\n",
    "\n",
    "tokenized_data_text = tokenizer_data.texts_to_sequences(input_pre)\n",
    "vec_data = pad_sequences(tokenized_data_text, padding = 'post', maxlen = 800)\n",
    "\n",
    "# Save model to pickle file\n",
    "pickle.dump(tokenizer_data, open(\"tokenizer_data.pkl\", \"wb\"))\n",
    "\n",
    "print('input data.shape', vec_data.shape)\n",
    "data_vocab_size = len(tokenizer_data.word_index)+1\n",
    "print('data_vocab_size: ', data_vocab_size)\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(vec_data, label_tf, test_size = 0.2, random_state = 42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.1, random_state = 42)\n",
    "print('training sample: ', len(X_train))\n",
    "print('validation sample: ', len(X_val))\n",
    "print('test_sample: ', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WgWEiFeWyJ_k"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architechture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wBcVpCSMyL8H",
    "outputId": "739da879-7afd-42d4-a664-73475fb5923a"
   },
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling1D,Conv1D, GlobalMaxPooling1D\n",
    "from unicodedata import bidirectional\n",
    "def generate_model():\n",
    "    dropout_threshold = 0.4\n",
    "    input_dim = data_vocab_size\n",
    "    output_dim = 50\n",
    "    input_length = 800\n",
    "    initializer = tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "    input_layer = Input(shape = (input_length))\n",
    "    feature = Embedding(input_dim = input_dim, output_dim = output_dim, input_length = input_length, embeddings_initializer = 'GlorotNormal')(input_layer)\n",
    "\n",
    "    cnn_feature = Conv1D(filters = 50, kernel_size = 3, padding = 'same', activation = 'relu')(feature)\n",
    "    cnn_feature = MaxPooling1D()(cnn_feature)\n",
    "    cnn_feature = Dropout(dropout_threshold)(cnn_feature)\n",
    "    cnn_feature = Conv1D(filters = 50, kernel_size = 3, padding = 'same', activation = 'relu')(cnn_feature)\n",
    "    cnn_feature = MaxPooling1D()(cnn_feature)\n",
    "    cnn_feature = LayerNormalization()(cnn_feature)\n",
    "    cnn_feature = Dropout(dropout_threshold)(cnn_feature)\n",
    "\n",
    "\n",
    "    bi_lstm_feature = Bidirectional(LSTM(units = 50, dropout = dropout_threshold, return_sequences = True, kernel_initializer = initializer), merge_mode = 'concat')(feature)\n",
    "    bi_lstm_feature = MaxPooling1D()(bi_lstm_feature)\n",
    "\n",
    "    bi_lstm_feature = Bidirectional(GRU(units = 50, dropout = dropout_threshold, return_sequences = True, kernel_initializer = initializer), merge_mode = 'concat')(bi_lstm_feature)\n",
    "    bi_lstm_feature = MaxPooling1D()(bi_lstm_feature)\n",
    "    bi_lstm_feature = LayerNormalization()(bi_lstm_feature)\n",
    "\n",
    "    combine_feature = tf.keras.layers.Concatenate()([cnn_feature, bi_lstm_feature])\n",
    "    combine_feature = GlobalMaxPooling1D()(combine_feature)\n",
    "    combine_feature = LayerNormalization()(combine_feature)\n",
    "\n",
    "    classifier = Dense(90, activation = 'relu')(combine_feature)\n",
    "    classifier = Dropout(0, 2)(classifier)\n",
    "    classifier = Dense(70, activation = 'relu')(classifier)\n",
    "    classifier = Dropout(0, 2)(classifier)\n",
    "    classifier = Dense(50, activation = 'relu')(classifier)\n",
    "    classifier = Dropout(0, 2)(classifier)\n",
    "    classifier = Dense(30, activation = 'relu')(classifier)\n",
    "    classifier = Dropout(0, 2)(classifier)\n",
    "    classifier = Dense(3, activation = 'softmax')(classifier)\n",
    "\n",
    "    model = tf.keras.Model(inputs = input_layer, outputs = classifier)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = generate_model()\n",
    "adam = Adam(learning_rate = 0.001)\n",
    "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architechture Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qb6TdviDOjOe",
    "outputId": "b90940d8-7127-4a13-daf6-7d1e288118c6"
   },
   "outputs": [],
   "source": [
    "dot_img_file = \"./images/model_visualize.png\"\n",
    "tf.keras.utils.plot_model(model, to_file = dot_img_file, show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3lLjkl9jyMJY",
    "outputId": "93d0f0f9-c823-48e4-8953-4c0c196ab9e4"
   },
   "outputs": [],
   "source": [
    "callback_model = tf.keras.callbacks.ModelCheckpoint('model_cnn_bilstm.h5', monitor = 'val_loss')\n",
    "history = model.fit(x = X_train, y = y_train, validation_data = (X_val, y_val), epochs = 10, callbacks = [callback_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ge41AiPgyMWX",
    "outputId": "192c8830-d52e-4141-a9a7-9244522dbb82"
   },
   "outputs": [],
   "source": [
    "model.load_weights('model_cnn_bilstm.h5')\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nJK38t0yOWZ"
   },
   "source": [
    "# Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "yhhyr4eNyPa5",
    "outputId": "7b988e92-3179-4f9b-c368-b4e8b5b0dbaf"
   },
   "outputs": [],
   "source": [
    "def preprocess_raw_input(raw_input, tokenizer):\n",
    "    input_text_pre = list(tf.keras.preprocessing.text.text_to_word_sequence(raw_input))\n",
    "    input_text_pre = ' '.join(input_text_pre)\n",
    "    input_text_pre_accent = ViTokenizer.tokenize(input_text_pre)\n",
    "    print('Text preprocessed: ',input_text_pre_accent)\n",
    "    tokenized_data_text = tokenizer.texts_to_sequences([input_text_pre_accent])\n",
    "    vec_data = pad_sequences(tokenized_data_text, padding = 'post', maxlen = 800)\n",
    "    return vec_data\n",
    "\n",
    "def inference_model(input_feature, model):\n",
    "    output = model(input_feature).numpy()[0]\n",
    "    label_list = ['NEG', 'NEU', 'POS']\n",
    "    res = dict(zip(label_list, output))\n",
    "    result = output.argmax()\n",
    "    conf = float(output.max())\n",
    "    label_dict = {'NEG': 0, 'NEU': 1, 'POS': 2}\n",
    "    label = list(label_dict.keys())\n",
    "    return label[int(result)], conf, res\n",
    "\n",
    "\n",
    "def prediction(raw_input, tokenizer, model):\n",
    "    input_model = preprocess_raw_input(raw_input, tokenizer_data)\n",
    "    result, conf,res = inference_model(input_model, model)\n",
    "\n",
    "    return result, conf, res\n",
    "\n",
    "my_model = generate_model()\n",
    "my_model = load_model('model_cnn_bilstm.h5')\n",
    "\n",
    "with open(r'tokenizer_data.pkl', 'rb') as input_file:\n",
    "    my_tokenizer = pickle.load(input_file)\n",
    "\n",
    "while(True):\n",
    "    text = input()\n",
    "    if text == 'end':\n",
    "        break\n",
    "    else:\n",
    "        print(str(prediction(text, my_tokenizer, my_model)) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
